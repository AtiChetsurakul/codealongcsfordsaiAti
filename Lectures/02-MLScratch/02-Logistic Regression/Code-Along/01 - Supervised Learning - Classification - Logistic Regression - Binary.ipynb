{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Science and Artificial Intelligence\n",
    "\n",
    "## Supervised Learning - Classification - Logistic Regression - Binary\n",
    "\n",
    "### Readings: \n",
    "- [GERON] Ch4\n",
    "- [VANDER] Ch5\n",
    "- [HASTIE] Ch4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Logistic regression is an supervised algorithm for solving classification problem where outcome (target) is discrete.   The idea behind is that $\\boldsymbol{\\theta}^T\\mathbf{x}$ will return a continous value and thus may not be suitable for classification task.  However, if we can find one function $g$ such that\n",
    "\n",
    "$$g(\\boldsymbol{\\theta}^T\\mathbf{x}) = [0, 1]$$\n",
    "\n",
    "then we can define our hypothesis function as $g$ and optimize accordingly based on some cost function.\n",
    "\n",
    "It happens that $g$ (and also our hypothesis function $\\mathbf{h}$) can be defined as the sigmoid (logit) function as the following:\n",
    "\n",
    "$$ h = g(\\boldsymbol{\\theta}^T\\mathbf{x}) = \\frac{1}{1+e^{-\\boldsymbol{\\theta}^T\\mathbf{x}}} $$\n",
    "\n",
    "**Trivials**: \n",
    "$e$ is a really convenient number for math, for example whenever you take the derivative of $e^x$, you get $e^x$ back again.  It's the only function on Earth that will do that.  Also, $e^x$ always give you positive numbers, thus it is no surprise this $e$ was often used in probability/statistics.  Last, it is convenient to apply $\\log$ in any optimization problem including $e$ since it will cancel it nicely and will also not change the optimization answer since $\\log$ is monotically increasing.  Btw, the common log base we use in natural log, but it really does not matter because the base is merely a constant.\n",
    "\n",
    "Let's see how does it look in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the derivative using quotient rule is        \n",
    "\n",
    "$$ (\\frac{f}{g})' = \\frac{f'g - fg'}{g^2}$$\n",
    "\n",
    "Given sigmoid function as\n",
    "\n",
    "$$ g(x) = \\frac{1}{1+e^{-x}} $$\n",
    "\n",
    "Thus the derivative of sigmoid function is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\frac{dg}{dx} &= \\frac{0(1 + e^{-x}) - (-1)(e^{-x}))}{(1 + e^{-x})^2} \\\\\n",
    "    &= \\frac{e^{-x}}{(1 + e^{-x})^2}  = \\frac{e^{-x} + 1 - 1}{(1 + e^{-x})^2} \\\\\n",
    "    &= \\frac{1}{(1 + e^{-x})} - \\frac{1}{(1 + e^{-x})^2} \\\\\n",
    "    &= \\frac{1}{(1 + e^{-x})} \\big(1 - \\frac{1}{(1 + e^{-x})}\\big)\\\\\n",
    "    &= g(1 - g)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let's look at the gradient by modifying our sigmoid function a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trivials**: As you can see, the greatest gradient possible is 0.25.  Thus it means that in a gradient descent update, the update speed will be restricted by this value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we had the following function\n",
    "\n",
    "$$ \\boldsymbol{\\theta}^T\\mathbf{x} = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} $$\n",
    "\n",
    "Given some point ($x_{1}$,$x_{2}$), if we plugged it to our sigmoid function, the equation could output a positive result (for one class), negative result (for the other class), or 0 (the point lies right on the decision boundary).\n",
    "\n",
    "For example, given ($x_{1} = 3$, $x_{2} = 4$) and ($\\theta_{1}$ = 1, $\\theta_{2}$ = 2) (let's ignore $\\theta_{0}$ for simplicity), the following code performs a sigmoid of $\\boldsymbol{\\theta}^T\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where are we so far?\n",
    "\n",
    "Well, we have so far motivated the followings:\n",
    "\n",
    "1. We need a squashing function $g$ to use in classification problem\n",
    "2. We will also go through together different possible squashing function including sigmoid, tanh, relu, and leaky relu\n",
    "\n",
    "For now, we shall use only sigmoid function, since we will be talking mainly about logistic regression.  But we shall go back to these other activation functions later on in the course.\n",
    "\n",
    "Here, we shall explore three different variants of logistic regression:\n",
    "1. Binary Logistic Regression\n",
    "2. Multinomial (multiclass) Logistic Regression\n",
    "3. Logistic Regression with Newton-Raphson method\n",
    "\n",
    "Last, we shall explore the sklearn way.\n",
    "\n",
    "**Be warned**: There will be a lot of equations but they are necessary to understand in order to do the implementation.  For some obvious derivations, I will leave them as your exercise, but if you feel inimidated, ask me in class or come to my office."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Binary Logistic Regression\n",
    "\n",
    "Logistic regression is a binary classification algorithm by simply finding a best fitted line that separates two dataset.  In order to squash the output to a value between 0 and 1, logistic regression used a function called logit function (or sigmoid function)\n",
    "\n",
    "### Scratch\n",
    "\n",
    "**Implementation steps:**\n",
    "    \n",
    "1. Prepare your data\n",
    "    - add intercept\n",
    "    - $\\mathbf{X}$ and $\\mathbf{y}$ and $\\mathbf{w}$ in the right shape\n",
    "        - $\\mathbf{X}$ -> $(m, n)$\n",
    "        - $\\mathbf{y}$ -> $(m, )$\n",
    "        - $\\mathbf{w}$ -> $(n, )$\n",
    "        - where $m$ is number of samples\n",
    "        - where $n$ is number of features\n",
    "    - train-test split\n",
    "    - feature scale\n",
    "    - clean out any missing data\n",
    "    - (optional) feature engineering\n",
    "2. Predict and calculate the loss\n",
    "    - The loss function is the *cross entropy* defined as\n",
    "    $$J = - (\\sum_{i=1}^m y^{(i)}\\log(h^{(i)}) + (1-y^{(i)})\\log(1-h^{(i)}))$$\n",
    "    where h is defined as the sigmoid function as\n",
    "    $$h = \\frac{1}{1+e^{-\\boldsymbol{\\theta}^T\\mathbf{x}}}$$\n",
    "3. Calculate the gradient based on the loss\n",
    "    - The gradient of $\\theta_j$ is defined as\n",
    "        $$\\frac{\\partial J}{\\partial \\theta_j} = \\sum_{i=1}^{m}(h^{(i)}-y^{(i)})x_j$$\n",
    "    - This can be derived by knowing that \n",
    "        $$J= - (y \\log h + (1 - y) \\log (1-h))$$\n",
    "        $$h = \\frac{1}{1+e^{-g}}$$\n",
    "        $$g = \\theta^Tx$$\n",
    "    - Thus, gradient of $J$ in respect to some $\\theta_j$ is\n",
    "        $$\\frac{\\partial J}{\\partial \\theta_j} = \\frac{\\partial J}{\\partial h} \\frac{\\partial h}{\\partial g} \\frac{\\partial g}{\\partial \\theta_j}$$\n",
    "      where\n",
    "        $$\\frac{\\partial J}{\\partial h} = \\frac{h - y}{h(1-h)}$$\n",
    "        $$\\frac{\\partial h}{\\partial g} = h(1-h)$$\n",
    "        $$\\frac{\\partial g}{\\partial \\theta_j} = x_j$$\n",
    "    - Thus, \n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\frac{\\partial J}{\\partial \\theta_j} &= \\frac{\\partial J}{\\partial h} \\frac{\\partial h}{\\partial g} \\frac{\\partial g}{\\partial \\theta_j}\\\\\n",
    "   &= \\frac{h - y}{h(1-h)} * h(1-h) * x_j\\\\\n",
    "   &= (h - y)x_j\\\\\n",
    "   \\end{aligned}$$\n",
    "4. Update the theta with this update rule\n",
    "    $$\\theta_j := \\theta_j - \\alpha * \\frac{\\partial J}{\\partial \\theta_j}$$\n",
    "    where $\\alpha$ is a typical learning rate range between 0 and 1\n",
    "5. Loop 2-4 until max_iter is reached, or the difference between old loss and new loss are smaller than some predefined threshold tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare your data\n",
    "\n",
    "#### 1.1 Get your X and y in the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Feature scale your data to reach faster convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Train test split your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Add intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Fit your algorithm \n",
    "\n",
    "#### 1. Define your algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification metrics\n",
    "\n",
    "Let us study some classification metrics that are quite different from the $r^2$ or $mse$ that we see from the regression.  Let me define a confusion matrix that looks like this:\n",
    "\n",
    "<code>\n",
    "\t\t \t    Actual\n",
    "\t\t\t    +\t   -\n",
    "Predicted +     TP     FP\n",
    "          -     FN     TN\n",
    "</code>\n",
    "\n",
    "TP is defined as true positives, FP as false positives, FN as false negatives, and TN as true negatives.\n",
    "\n",
    "#### Accuracy, Recall, Precision, F1\n",
    "\n",
    "Accuracy is straightforward\n",
    "\n",
    "$$ Accuracy = \\frac{TP + TN}{TP + TN + FP + FN} $$\n",
    "\n",
    "Accuracy is mostly avoided, unless your model is really balanced of both positives and negatives.  Instead, more useful classification metrics would be precision, recall, and f1-score\n",
    "\n",
    "$$ Precision = TP / (TP + FP) $$\n",
    "\n",
    "Precision is useful as metric when you want to prioritize removing false positive.  Example is search engine in which you do not want to return any search results that are \"false positive\"\n",
    "\n",
    "$$ Recall = TP / (TP + FN) $$\n",
    "\n",
    "Recall is useful as metric when you want to prioritize removing false negative.  Example is cancer detection in which you do not want to miss detecting any real positive (i.e., false negative).\n",
    "\n",
    "$$ F1 = 2 x \\frac{Precision * Recall}{Precision+Recall} $$\n",
    "\n",
    "F1 is simply seeking a balance between Precision and Recall.  Also F1 is good metric when there is an uneven class distribution (large number of actual negatives)\n",
    "\n",
    "To get accuracy, recall, precision and f1 score, we can use **sklearn.metrics.classification_report**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC\n",
    "\n",
    "An ROC curve shows the performance of one classification model at **all classification thresholds**. For example, if we set threshold to 0.4, then anything less than 0.4 will be negative class, and otherwise positive class.  To build the ROC curve, you iterate all possible threshold, and collect the TP, FP, TN, TP of all possible threshold.\n",
    "\n",
    "ROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis, where\n",
    "\n",
    "$$ TPR = TP / (TP + FN) $$\n",
    "\n",
    "$$ FPR = FP / (FP + TN) $$\n",
    "\n",
    "This means that the top left corner of the plot is the “ideal” point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better.\n",
    "\n",
    "To get area score under the curve, we can use **sklearn.metrics.roc_auc_score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-Recall\n",
    "\n",
    "Davis and Goadrich in this paper (https://ftp.cs.wisc.edu/machine-learning/shavlik-group/davis.icml06.pdf) propose that Precision-Recall (PR) metric will be more informative than ROC when dealing with highly skewed datasets. Because Precision is directly influenced by class imbalance so the Precision-recall are better to highlight differences between models for highly imbalanced data sets. When you compare different models with imbalanced settings, the area under the Precision-Recall curve will be more sensitive than the area under the ROC curve.\n",
    "\n",
    "Example of drawback of ROC curve\n",
    "\n",
    "- $TPR = TP / (TP + FN) $\n",
    "- $FPR = FP / (FP + TN) $\n",
    "\n",
    "======balanced data=====\n",
    "- n_sample = 500\n",
    "- pos = 250\n",
    "- neg = 250\n",
    "- Given the following confusion matrix\n",
    "\n",
    "<code>\n",
    "\t\t\tActual\n",
    "\t\t\t  +\t     -\n",
    "Predict.+     125     125\n",
    "        -     0       250\n",
    "</code>\n",
    "\n",
    "- $TPR = 125 / (125 + 0) = 1$\n",
    "- $FPR = 125 / 125 + 250 = 0.3$\n",
    "\n",
    "Looks ok!\n",
    "\n",
    "=====imbalanced data=======\n",
    "- n_sample = 500\n",
    "- pos = 30\n",
    "- neg = 470\n",
    "- Given the following confusion matrix\n",
    "\n",
    "<code>\n",
    "\t\t\tActual\n",
    "\t\t\t  +\t     -\n",
    "Predict.+     15     15\n",
    "        -     0      470\n",
    "</code>\n",
    "\n",
    "- $TPR = 15 / (15 + 0)$ = 1\n",
    "- $FPR = 15/ (15 + 470) {\\approx} 0$\n",
    "\n",
    "Perfect model??  How?  Because the amount of wrong positives is undermined by the great amount of negatives\n",
    "\n",
    "====Precision-Recall curve works much better for imbalanced=====\n",
    "\n",
    "- Precision =  TP / (TP + FP)\n",
    "- Recall = TP / (TP + FN)\n",
    "\n",
    "- Precision = 15 / (15 + 15) = 0.5. #minimize false positive\n",
    "- Recall = 15 / (15 + 0) = 1.   #minimize false negative\n",
    "\n",
    "Reflect much better!\n",
    "\n",
    "For precision-recall metric, we can use **sklearn.metrics.average_precision_score** which compute the ratio between recall and precision (read more here -->https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py). \n",
    "\n",
    "**Note**: sklearn version of average_precision_score are typically used in binary classification to study the output of a classifier. In order to extend the precision-recall curve and average precision to multi-class or multi-label classification, it is necessary to **binarize** the output. I have demonstrated this at the multinomial logistic regression part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === Task ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Put everything into a class called LogisticRegression. The training method should be \"minibatch\".\n",
    "\n",
    "2. Perform a classification on the data given above.\n",
    "\n",
    "3. Plot training losses as number of iters increases.\n",
    "\n",
    "4. Write a class called classification_report containing 4 functions (Accuracy, Recall, Precision, F1) and use it to evaluate your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
